{"metadata":{"colab":{"collapsed_sections":["lnUmkwSbY0Ho","qg4JIKs4EYtQ","GLRub0wZY0Hs","Zc1A7_xcwiT5","3cP79coczzan","hI6wj5hrz9vJ","txfmuahS0Apx","1nu4ISUMGt-J","AOSUt5iox8B6","TULzSmkZxgEn","PfZPlnRjjmOJ","oe_g0pXw21Tn","gB79UDNM8UOZ"],"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"widgets":{"application/vnd.jupyter.widget-state+json":{"31260ed6c1f744d5b7c158cbca479e88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_066d73f036a045e68be9478e9ea13399","IPY_MODEL_e306fe3156564bb0b34d3935e489a4c3","IPY_MODEL_59093bb8053445749de2219fa722866d"],"layout":"IPY_MODEL_df033e0d358d4ffaa1da1f3c941407e8"}},"066d73f036a045e68be9478e9ea13399":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbc4330051994a02a9cdf5b9a27c337b","placeholder":"​","style":"IPY_MODEL_328fec4bbd544fda96a6b126cc553b51","value":"  0%"}},"e306fe3156564bb0b34d3935e489a4c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a79a9ec2e8a407284ae17bb3af9fa58","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e7c0fa474ed4772a731f6240e3c42dd","value":0}},"59093bb8053445749de2219fa722866d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70d47ce411cc48c1b52003a2a1c33862","placeholder":"​","style":"IPY_MODEL_a14c404da4b946b1b02c131a50d8e460","value":" 0/4 [00:05&lt;?, ?it/s]"}},"df033e0d358d4ffaa1da1f3c941407e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbc4330051994a02a9cdf5b9a27c337b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"328fec4bbd544fda96a6b126cc553b51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a79a9ec2e8a407284ae17bb3af9fa58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e7c0fa474ed4772a731f6240e3c42dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70d47ce411cc48c1b52003a2a1c33862":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a14c404da4b946b1b02c131a50d8e460":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83a17996793f4d79b2b7704f2ce52954":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2900f327cca84cd9bd42a75b3d39e7cf","IPY_MODEL_229705beff58452895896475458cf6b9","IPY_MODEL_da4e71784ab8416e897018d773dda606"],"layout":"IPY_MODEL_ee95d38e59324705b7973f0e17d08aee"}},"2900f327cca84cd9bd42a75b3d39e7cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31285b0d954b4a209c37ae991c97d4fc","placeholder":"​","style":"IPY_MODEL_e6a9afeb0ad5476f95882cf673bec0b3","value":"100%"}},"229705beff58452895896475458cf6b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9ae1805b98848c19c2169ee8adcd048","max":6387309499,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9319ec855804760ba8a7fa9be16134b","value":6387309499}},"da4e71784ab8416e897018d773dda606":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e77662c9054b3c9191b55f03d400cb","placeholder":"​","style":"IPY_MODEL_832f93935b934ded8efe826cc0c4a769","value":" 5.95G/5.95G [04:53&lt;00:00, 21.7MB/s]"}},"ee95d38e59324705b7973f0e17d08aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31285b0d954b4a209c37ae991c97d4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6a9afeb0ad5476f95882cf673bec0b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9ae1805b98848c19c2169ee8adcd048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9319ec855804760ba8a7fa9be16134b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29e77662c9054b3c9191b55f03d400cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"832f93935b934ded8efe826cc0c4a769":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"484b1873c4aa4eb687d75b7d0efea030":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb9b58cb4621463aab2cf9fb95e09a7d","IPY_MODEL_3ca351f8920d471b8f5f507b3fa48a44","IPY_MODEL_b22b06119c6e48b490f89d9adac640a4"],"layout":"IPY_MODEL_26a43c0c64d045fea785a9b327da9209"}},"eb9b58cb4621463aab2cf9fb95e09a7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ecfade5b4c4aab9562bff7086dca11","placeholder":"​","style":"IPY_MODEL_2cf5ecf86bdc4ba3b5c867adc1c2e80f","value":"100%"}},"3ca351f8920d471b8f5f507b3fa48a44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72bd9493ee524510b5f0cea69ef32519","max":346663984,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6e71cfbdc094ff983f3285250ad47b5","value":346663984}},"b22b06119c6e48b490f89d9adac640a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df67c0b06e94040933d440cf8bf5b08","placeholder":"​","style":"IPY_MODEL_1655a08ef4ec46a692ab59ee2c797ede","value":" 331M/331M [00:16&lt;00:00, 21.2MB/s]"}},"26a43c0c64d045fea785a9b327da9209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ecfade5b4c4aab9562bff7086dca11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf5ecf86bdc4ba3b5c867adc1c2e80f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72bd9493ee524510b5f0cea69ef32519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6e71cfbdc094ff983f3285250ad47b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3df67c0b06e94040933d440cf8bf5b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1655a08ef4ec46a692ab59ee2c797ede":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3a09bf9e5c2489d8ac8989f6a0904dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca1a0f3f22cd4907b5b2abf891783ed5","IPY_MODEL_520a77acd09b43fdb6167f312b1695e4","IPY_MODEL_7b14d1d50416401588904444d26a0b1a"],"layout":"IPY_MODEL_d789b389030e451aa59f346cf2a6a6b2"}},"ca1a0f3f22cd4907b5b2abf891783ed5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73149239d2f54a4581b03bda95f0af1c","placeholder":"​","style":"IPY_MODEL_41b358772ba44b42b87c0e6c91793348","value":"  0%"}},"520a77acd09b43fdb6167f312b1695e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_773a434795d3403cb8c7ccfb0fe5833d","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ac15917a5c541e1bbe584ca5855b9f9","value":0}},"7b14d1d50416401588904444d26a0b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_496bd08c960e46fd8047ff076932dc9b","placeholder":"​","style":"IPY_MODEL_b1f02a4b976e4638bff87944d454ba5c","value":" 0/10 [00:00&lt;?, ?it/s]"}},"d789b389030e451aa59f346cf2a6a6b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73149239d2f54a4581b03bda95f0af1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b358772ba44b42b87c0e6c91793348":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"773a434795d3403cb8c7ccfb0fe5833d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ac15917a5c541e1bbe584ca5855b9f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"496bd08c960e46fd8047ff076932dc9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1f02a4b976e4638bff87944d454ba5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Homework #1: train a CTC speech recognition model\n\nIn lecture you have examined the basics of speech recognition and covered the Connectionist Temporal Classification (CTC) model in detail. You are now ready to train your first \"adult\" speech recognition system!\n\nIn seminar 3 you implemented the CTC forward and backward algorithms in order to calculate the CTC loss and study the diffusion of probability in a CTC trellis. Also you implemented a greedy decoder and a prefix beam-search decoder\n\nIn this homework you will implement and train a CTC speech recognition model on a subset of the LibriSpeech corpus. This task will involve:\n\n- Creating a dataloader\n- Implementing a and training a Neural Network for CTC\n  * DNN\n  * LSTM\n  * BiLSTM\n- Comparing the Properties of these models","metadata":{"id":"EhkTsE_rVd-n"}},{"cell_type":"markdown","source":"# Setup - Install package, download files, etc...","metadata":{"id":"qg4JIKs4EYtQ"}},{"cell_type":"code","source":"# # uncomment if needed. If you run the notebook in Colab, all these libraries are pre-installed\n# !pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n# !pip install numpy==1.17.5 matplotlib==3.3.3 tqdm==4.54.0","metadata":{"id":"Gk1mFIiwve6R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c5a3234-5613-4d5a-b755-6d68c59180cc","execution":{"iopub.status.busy":"2023-03-27T15:02:03.245890Z","iopub.execute_input":"2023-03-27T15:02:03.246274Z","iopub.status.idle":"2023-03-27T15:02:03.267399Z","shell.execute_reply.started":"2023-03-27T15:02:03.246241Z","shell.execute_reply":"2023-03-27T15:02:03.266559Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install arpa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwuUeuXXBDPl","outputId":"24cacce8-286e-45bb-b721-943f4033c1e2","execution":{"iopub.status.busy":"2023-03-27T15:10:08.017490Z","iopub.execute_input":"2023-03-27T15:10:08.018189Z","iopub.status.idle":"2023-03-27T15:10:20.612971Z","shell.execute_reply.started":"2023-03-27T15:10:08.018149Z","shell.execute_reply":"2023-03-27T15:10:20.611705Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting arpa\n  Downloading arpa-0.1.0b4-py3-none-any.whl (9.6 kB)\nInstalling collected packages: arpa\nSuccessfully installed arpa-0.1.0b4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install wandb -qqq","metadata":{"id":"HN6poM45AAXH","execution":{"iopub.status.busy":"2023-03-27T15:10:20.616412Z","iopub.execute_input":"2023-03-27T15:10:20.617472Z","iopub.status.idle":"2023-03-27T15:10:29.859234Z","shell.execute_reply.started":"2023-03-27T15:10:20.617426Z","shell.execute_reply":"2023-03-27T15:10:29.857881Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#!L\nimport math\nimport os\nimport shutil\nimport string\nimport time\nfrom collections import defaultdict\nfrom typing import List, Tuple, TypeVar, Optional, Callable, Iterable\n\nimport arpa\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchaudio\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport wandb\nfrom matplotlib.colors import LogNorm\nfrom torch import optim\nfrom tqdm.notebook import tqdm","metadata":{"id":"IM01xHP7Y0Hi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"291857a0-c821-469c-c6e1-3d879f0e5514","execution":{"iopub.status.busy":"2023-03-27T15:10:29.861029Z","iopub.execute_input":"2023-03-27T15:10:29.861439Z","iopub.status.idle":"2023-03-27T15:10:33.155299Z","shell.execute_reply.started":"2023-03-27T15:10:29.861398Z","shell.execute_reply":"2023-03-27T15:10:33.154117Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/input/current\")","metadata":{"execution":{"iopub.status.busy":"2023-03-27T15:10:33.158315Z","iopub.execute_input":"2023-03-27T15:10:33.159927Z","iopub.status.idle":"2023-03-27T15:10:33.166329Z","shell.execute_reply.started":"2023-03-27T15:10:33.159880Z","shell.execute_reply":"2023-03-27T15:10:33.165390Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import utils as utils   # Change relative path if needed","metadata":{"id":"t9lYheNjY0Hn","execution":{"iopub.status.busy":"2023-03-27T15:10:33.167527Z","iopub.execute_input":"2023-03-27T15:10:33.167909Z","iopub.status.idle":"2023-03-27T15:10:33.185706Z","shell.execute_reply.started":"2023-03-27T15:10:33.167866Z","shell.execute_reply":"2023-03-27T15:10:33.184571Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2023-03-27T15:10:33.188339Z","iopub.execute_input":"2023-03-27T15:10:33.189226Z","iopub.status.idle":"2023-03-27T15:10:33.193585Z","shell.execute_reply.started":"2023-03-27T15:10:33.189188Z","shell.execute_reply":"2023-03-27T15:10:33.192516Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Seminar 3 recap: CTC Forward-Backward Algorithm + Soft alignment","metadata":{"id":"GLRub0wZY0Hs"}},{"cell_type":"markdown","source":"## CTC Forward Algorithm","metadata":{"id":"1nu4ISUMGt-J"}},{"cell_type":"code","source":"# Helper functions\nBLANK_SYMBOL = \"_\"\n\nclass Tokenizer:\n    \"\"\"\n    Maps characters to integers and vice versa\n    \"\"\"\n    def __init__(self):\n        self.char_map = {}\n        self.index_map = {}\n        for i, ch in enumerate([\"'\", \" \"] + list(string.ascii_lowercase) + [BLANK_SYMBOL]):\n            self.char_map[ch] = i\n            self.index_map[i] = ch\n        \n    def text_to_indices(self, text: str) -> List[int]:\n        return [self.char_map[ch] for ch in text]\n\n    def indices_to_text(self, labels: List[int]) -> str:                                                                                                                                                                                                                                 \n        return \"\".join([self.index_map[i] for i in labels])\n    \n    def get_symbol_index(self, sym: str) -> int:\n        return self.char_map[sym]\n    \n\ntokenizer = Tokenizer()\n\nNEG_INF = -float(\"inf\")\n\n\ndef logsumexp(*args) -> float:\n    \"\"\"\n    Log-sum-exp trick for log-domain calculations\n    See for details: https://en.wikipedia.org/wiki/LogSumExp\n    \"\"\"\n    if all(a == NEG_INF for a in args):\n        return NEG_INF\n    a_max = max(args)\n    lsp = math.log(sum(math.exp(a - a_max) for a in args))\n    return a_max + lsp\n\n\ndef modify_sequence(sequence: List[int], blank_idx: int) -> List[int]:\n    \"\"\"\n    Modifies sequence which with START, END blanks and between each character\n    \"\"\"\n    modified_sequence = []\n    \n    for idx in sequence:\n        modified_sequence += [blank_idx, idx]\n        \n    modified_sequence.append(blank_idx)\n    return modified_sequence","metadata":{"id":"HgRpr3bjY0Hv","execution":{"iopub.status.busy":"2023-03-27T15:10:33.194991Z","iopub.execute_input":"2023-03-27T15:10:33.195409Z","iopub.status.idle":"2023-03-27T15:10:33.210235Z","shell.execute_reply.started":"2023-03-27T15:10:33.195369Z","shell.execute_reply":"2023-03-27T15:10:33.209067Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#!L\n\ndef forward_algorithm(sequence: List[int], matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    :param sequence: a string converted to an index array by Tokenizer\n    :param matrix: A matrix of shape (K, T) with probability distributions over phonemes at each moment of time.\n    :return: the result of the forward pass of shape (2 * len(sequence) + 1, T)\n    \"\"\"\n    # Turn probs into log-probs\n    matrix = np.log(matrix)\n    \n    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n    mod_sequence = modify_sequence(sequence, blank)\n\n    # Initialze\n    # (2L + 1) x T \n    alphas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n\n    for t in range(matrix.shape[1]):\n        for s in range(len(mod_sequence)):\n            # First Step\n            ch = mod_sequence[s]\n            if t == 0:\n                if s != 0 and s != 1:\n                    alphas[s][t] = NEG_INF\n                else:\n                    alphas[s][t] = matrix[ch][t]\n                \n            # Upper diagonal zeros\n            elif s < alphas.shape[0] - 2 * (alphas.shape[1]-t)-1:# CONDITION\n                alphas[s][t] = NEG_INF\n            else:\n                # Need to do this stabily\n                if s == 0:\n                    alphas[s][t] = alphas[s][t-1] + matrix[ch][t]\n                elif s == 1:\n                    alphas[s][t] = logsumexp(alphas[s][t-1], alphas[s-1][t-1]) + matrix[ch][t]\n                else:\n                    if ch == blank or ch == mod_sequence[s-2]:\n                        alphas[s][t] = logsumexp(alphas[s][t-1], alphas[s-1][t-1]) + matrix[ch][t]\n                    else:\n                        alphas[s][t] = logsumexp(alphas[s][t-1], alphas[s-1][t-1], alphas[s-2][t-1]) + matrix[ch][t]\n    return alphas","metadata":{"id":"FSU94H8-xJMw","execution":{"iopub.status.busy":"2023-03-27T15:10:33.212527Z","iopub.execute_input":"2023-03-27T15:10:33.213241Z","iopub.status.idle":"2023-03-27T15:10:33.228059Z","shell.execute_reply.started":"2023-03-27T15:10:33.213198Z","shell.execute_reply":"2023-03-27T15:10:33.227142Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## The CTC Backward Algorithm","metadata":{"id":"AOSUt5iox8B6"}},{"cell_type":"code","source":"def backward_algorithm(sequence: List[int], matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    :param sequence: a string converted to an index array by Tokenizer\n    :param matrix: A matrix of shape (K, T) with probability distributions over phonemes at each moment of time.\n    :return: the result of the backward pass of shape (2 * len(sequence) + 1, T)\n    \"\"\"\n    matrix = np.log(matrix)\n    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n    mod_sequence = modify_sequence(sequence, blank)\n    betas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n\n    for t in reversed(range(matrix.shape[1])):\n        for s in reversed(range(len(mod_sequence))):\n            # First Step\n            ch = mod_sequence[s]\n            if t == matrix.shape[1] - 1:\n                if s == betas.shape[0]-1 or s == betas.shape[0]-2:\n                    betas[s][t] = 0\n\n            # Lower Diagonal Zeros\n            elif s > 2 * t + 1:# CONDITION\n                betas[s][t] = NEG_INF\n            else:\n                if s == len(mod_sequence) - 1:\n                    betas[s][t] = betas[s][t+1] + matrix[ch][t]\n                elif s == len(mod_sequence) - 2:\n                    betas[s][t] = logsumexp(betas[s][t+1], betas[s+1][t+1]) + matrix[ch][t]\n                else:\n                    if ch == blank or ch == mod_sequence[s + 2]:\n                            betas[s][t] = logsumexp(betas[s][t+1], betas[s+1][t+1]) + matrix[ch][t]\n                    else:                \n                        betas[s][t] = logsumexp(betas[s][t+1], betas[s+1][t+1], betas[s+2][t+1]) + matrix[ch][t]\n    return betas","metadata":{"id":"hTaA3O8nHArw","execution":{"iopub.status.busy":"2023-03-27T15:10:33.232360Z","iopub.execute_input":"2023-03-27T15:10:33.232680Z","iopub.status.idle":"2023-03-27T15:10:33.245486Z","shell.execute_reply.started":"2023-03-27T15:10:33.232635Z","shell.execute_reply":"2023-03-27T15:10:33.244360Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Soft-Alignment\n","metadata":{"id":"TULzSmkZxgEn"}},{"cell_type":"code","source":"def soft_alignment(labels_indices: List[int], matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns the alignment coefficients for the input sequence\n    \"\"\"\n    alphas = forward_algorithm(labels_indices, matrix)\n    betas = backward_algorithm(labels_indices, matrix)\n\n    # Move from log space back to prob space\n    align = np.exp(alphas + betas)\n\n    # Normalize Alignment\n    align = align / np.sum(align, axis=0)\n\n    return align","metadata":{"id":"r9Xo-1tvHEBX","execution":{"iopub.status.busy":"2023-03-27T15:10:33.247201Z","iopub.execute_input":"2023-03-27T15:10:33.248044Z","iopub.status.idle":"2023-03-27T15:10:33.260334Z","shell.execute_reply.started":"2023-03-27T15:10:33.247907Z","shell.execute_reply":"2023-03-27T15:10:33.259375Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Greedy Best-Path Decoder\n","metadata":{"id":"pQNJqD8mx_0i"}},{"cell_type":"code","source":"#!L\ndef greedy_decoder(output: torch.Tensor, labels: List[torch.Tensor], \n                   label_lengths: List[int], collapse_repeated: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    :param output: torch.Tensor of Probs or Log-Probs of shape [batch, time, classes]\n    :param labels: list of label indices converted to torch.Tensors\n    :param label_lengths: list of label lengths (without padding)\n    :param collapse_repeated: whether the repeated characters should be deduplicated\n    :return: the result of the decoding and the target sequence\n    \"\"\"\n    blank_label = tokenizer.get_symbol_index(BLANK_SYMBOL)\n\n    # Get max classes\n    ########################\n    arg_maxes = output.argmax(dim=-1)\n    ########################\n\n    decodes = []\n    targets = []\n\n    # For targets and decodes remove repeats and blanks\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        true_labels = labels[i][:label_lengths[i]].tolist()\n        targets.append(tokenizer.indices_to_text(true_labels))\n\n        # Remove repeats, then remove blanks\n        for j, index in enumerate(args):\n            ########################\n            if j != 0:\n                if index == args[j-1]:\n                    continue\n            decode.append(int(index.cpu().detach()))    \n            ########################\n        ####\n        decode = [x for x in decode if x != blank_label]\n        ######\n        \n        decodes.append(tokenizer.indices_to_text(decode))\n    return decodes, targets","metadata":{"id":"qQhIqk30x4nv","execution":{"iopub.status.busy":"2023-03-27T15:10:33.263096Z","iopub.execute_input":"2023-03-27T15:10:33.264137Z","iopub.status.idle":"2023-03-27T15:10:33.275799Z","shell.execute_reply.started":"2023-03-27T15:10:33.264102Z","shell.execute_reply":"2023-03-27T15:10:33.274632Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Prefix Decoding With LM","metadata":{"id":"oe_g0pXw21Tn"}},{"cell_type":"code","source":"LanguageModel = TypeVar(\"LanguageModel\")\n# Helper function\n\nclass Beam:\n    def __init__(self, beam_size: int) -> None:\n        self.beam_size = beam_size\n        \n        fn = lambda : (NEG_INF, NEG_INF)\n        \n        # Store probs key - prefix, value - p_blank, p_not_blank for ? step\n        self.candidates = defaultdict(fn)\n        \n        # Store sorted by cumulative probability self.candidates\n        self.top_candidates_list = [\n            (\n                tuple(), \n                (0.0, NEG_INF) # log(p_blank) = 0, log(p_not_blank) = -inf\n            )\n        ]\n        \n    def get_probs_for_prefix(self, prefix: Tuple[int]) -> Tuple[float, float]:\n        p_blank, p_not_blank = self.candidates[prefix]\n        return p_blank, p_not_blank\n        \n    def update_probs_for_prefix(self, prefix: Tuple[int], next_p_blank: float, next_p_not_blank: float) -> None:\n        self.candidates[prefix] = (next_p_blank, next_p_not_blank)\n        \n    def update_top_candidates_list(self) -> None:\n        top_candidates = sorted(\n            self.candidates.items(), \n            key=lambda x: logsumexp(*x[1]), \n            reverse=True\n        )\n        self.top_candidates_list = top_candidates[:self.beam_size]\n        \n\ndef calculate_probability_score_with_lm(lm: LanguageModel, prefix: str) -> float:\n    text = tokenizer.indices_to_text(prefix).upper().strip()    # Use upper case for LM and remove the trailing space\n    lm_prob = lm.log_p(text)             \n    score = lm_prob / np.log10(np.e)    # Convert to natural log, as ARPA LM uses log10   \n    return score","metadata":{"id":"AqYtZjJhY0H0","execution":{"iopub.status.busy":"2023-03-27T15:10:33.277282Z","iopub.execute_input":"2023-03-27T15:10:33.277941Z","iopub.status.idle":"2023-03-27T15:10:33.288898Z","shell.execute_reply.started":"2023-03-27T15:10:33.277904Z","shell.execute_reply":"2023-03-27T15:10:33.287803Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#!L\n\ndef decode(probs: np.ndarray, beam_size: int = 5, lm: Optional[LanguageModel] = None, \n           prune: float = 1e-5, alpha: float = 0.1, beta: float = 2):\n    \"\"\"\n    :param probs: A matrix of shape (T, K) with probability distributions over phonemes at each moment of time.\n    :param beam_size: the size of beams\n    :lm: arpa language model\n    :prune: the minimal probability for a symbol at which it can be added to a prefix\n    :alpha: the parameter to de-weight the LM probability\n    :beta: the parameter to up-weight the length correction term\n    :return: the prefix with the highest sum of probabilites P_blank and P_not_blank\n    \"\"\"\n    T, S = probs.shape\n    probs = np.log(probs)\n    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n    space = tokenizer.get_symbol_index(\" \")\n    prune = NEG_INF if prune == 0.0 else np.log(prune)\n    \n    beam = Beam(beam_size)\n    # Итерируемся по оси времени\n    for t in range(T):\n        next_beam = Beam(beam_size)\n        \n        # Итерируемся по символам\n        for s in range(S):\n            p = probs[t, s]\n            # Prune the vocab - пропускаем символ, если вероятность оказаться в нем слишком мала на t-м щаге\n            if p < prune:   \n                continue\n            \n            # Итерируемся по варинатам, в которые можем пойти из текущего символа\n            # Сначала идут наиболее вероятные по сумме log(p_blank + p_not_blank) префиксы\n            # (p_blank, p_not_blank) - вероятности на предыдущем t-1 шаге\n            for prefix, (p_blank, p_not_blank) in beam.top_candidates_list:\n                # Текущий символ - бланк \n                if s == blank:\n                    # вероятности на текущем шаге\n                    p_b, p_nb = next_beam.get_probs_for_prefix(prefix)\n                    next_beam.update_probs_for_prefix(\n                        prefix=prefix,\n                        next_p_blank=logsumexp(p_b, p_blank + p, p_not_blank + p),\n                        next_p_not_blank=p_nb\n                    )\n                    continue\n\n                end_t = prefix[-1] if prefix else None\n                n_prefix = prefix + (s,)\n                \n                # Повторяющийся символ\n                if s == end_t:\n                    # Предыдущий символ - бланк\n                    p_b, p_nb = next_beam.get_probs_for_prefix(n_prefix)\n                    next_beam.update_probs_for_prefix(\n                        prefix=n_prefix,\n                        next_p_blank=p_b,\n                        next_p_not_blank=logsumexp(p_nb, p + p_blank)\n                    )\n                    # Предудщий символ не бланк\n                    p_b, p_nb = next_beam.get_probs_for_prefix(prefix)\n                    next_beam.update_probs_for_prefix(\n                        prefix=prefix,\n                        next_p_blank=p_b,\n                        next_p_not_blank=logsumexp(p_nb, p + p_not_blank)\n                    )\n                elif s == space and end_t is not None and lm is not None:\n                    # Символ - пробел и не первый, нужно применить языковую модель\n                    p_b, p_nb = next_beam.get_probs_for_prefix(n_prefix)\n                    score = calculate_probability_score_with_lm(lm, n_prefix)\n                    length = len(tokenizer.indices_to_text(prefix))\n                    \n                    next_beam.update_probs_for_prefix(\n                        prefix=n_prefix,         \n                        next_p_blank=p_b,\n                        next_p_not_blank=logsumexp(\n                            p_nb,\n                            p_blank + p + score * alpha + np.log(length) * beta,\n                            p_not_blank + p + score * alpha + np.log(length) * beta\n                        )  \n                    )\n                else:\n                    p_b, p_nb = next_beam.get_probs_for_prefix(n_prefix)\n                    next_beam.update_probs_for_prefix(\n                        prefix=n_prefix,\n                        next_p_blank=p_b,\n                        next_p_not_blank=logsumexp(p_nb, p_blank + p, p_not_blank + p)\n                    )\n\n        next_beam.update_top_candidates_list()\n        beam = next_beam\n\n    best = beam.top_candidates_list[0]\n    return best[0], -logsumexp(*best[1])\n\n\ndef beam_search_decoder(probs: np.ndarray, labels: List[List[int]], label_lengths: List[int], \n                        input_lengths: List[int], lm: LanguageModel, beam_size: int = 5,\n                        prune: float = 1e-3, alpha: float = 0.1, beta: float = 0.1):\n    probs = probs.cpu().detach().numpy()\n    decodes, targets = [], []\n    \n    for i, prob in enumerate(probs):\n        targets.append(tokenizer.indices_to_text(labels[i][:label_lengths[i]].tolist()))\n        int_seq, _ = decode(prob[:input_lengths[i]], lm=lm, beam_size=beam_size, prune=prune, alpha=alpha, beta=beta)\n        decodes.append(tokenizer.indices_to_text(int_seq))\n        \n    return decodes, targets","metadata":{"id":"SJ2pts572m5W","execution":{"iopub.status.busy":"2023-03-27T15:10:33.290593Z","iopub.execute_input":"2023-03-27T15:10:33.291289Z","iopub.status.idle":"2023-03-27T15:10:33.310973Z","shell.execute_reply.started":"2023-03-27T15:10:33.291246Z","shell.execute_reply":"2023-03-27T15:10:33.309979Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Homework 2 starts here: CTC Speech Recognition System\nYou can do this notebook in google collab, or use other GPU sources\n\n### Tasks\n\n- (20 points) Train ASR System, WER criterions: 60-50 -- 6 points, 50-40 -- 10 points, 40-35 -- 14 points, <=35 -- 20 points. + 1 bonus point per 1% WER below 30\n- (5 points) Compare performance of DNN, RNN and BiRNN models in terms of WER, training time and other properties\n- (5 points) Compare alignments obtained from DNN, RNN and BiRNN models","metadata":{"id":"doD9f6gZ2RXx"}},{"cell_type":"markdown","source":"## Implementing, training and evaluationg your CTC ASR model","metadata":{"id":"55HlLr7W63JJ"}},{"cell_type":"markdown","source":"### Create a Dataloader\n\nThe first step is to create a dataloader to download and load and preprocess LibriSpeech acoustic data. \n\nThe creative options you have at this stage are:\n\n* The sample rate and number of mel-bins.\n* Various forms of data agumentation","metadata":{"id":"yyU-wpIU67yu"}},{"cell_type":"code","source":"#!L\n# Download LibriSpeech 100hr training and test data\n\nif not os.path.isdir(\"./data\"):\n    os.makedirs(\"./data\")\n\ntrain_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\ntest_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["83a17996793f4d79b2b7704f2ce52954","2900f327cca84cd9bd42a75b3d39e7cf","229705beff58452895896475458cf6b9","da4e71784ab8416e897018d773dda606","ee95d38e59324705b7973f0e17d08aee","31285b0d954b4a209c37ae991c97d4fc","e6a9afeb0ad5476f95882cf673bec0b3","f9ae1805b98848c19c2169ee8adcd048","a9319ec855804760ba8a7fa9be16134b","29e77662c9054b3c9191b55f03d400cb","832f93935b934ded8efe826cc0c4a769","484b1873c4aa4eb687d75b7d0efea030","eb9b58cb4621463aab2cf9fb95e09a7d","3ca351f8920d471b8f5f507b3fa48a44","b22b06119c6e48b490f89d9adac640a4","26a43c0c64d045fea785a9b327da9209","c6ecfade5b4c4aab9562bff7086dca11","2cf5ecf86bdc4ba3b5c867adc1c2e80f","72bd9493ee524510b5f0cea69ef32519","e6e71cfbdc094ff983f3285250ad47b5","3df67c0b06e94040933d440cf8bf5b08","1655a08ef4ec46a692ab59ee2c797ede"]},"id":"qaeFHkHT2jqu","outputId":"57a99b7b-175a-4dd4-cce2-7b65a793df50","execution":{"iopub.status.busy":"2023-03-27T15:10:33.312460Z","iopub.execute_input":"2023-03-27T15:10:33.313080Z","iopub.status.idle":"2023-03-27T15:17:00.987604Z","shell.execute_reply.started":"2023-03-27T15:10:33.313044Z","shell.execute_reply":"2023-03-27T15:17:00.986567Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/5.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd74be003c640c29b8d829deebee961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/331M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff5ec11ed8f4906b820567d19ce26b0"}},"metadata":{}}]},{"cell_type":"code","source":"#!L\n# For train you can use SpecAugment data aug here.\ntrain_audio_transforms = nn.Sequential(\n    torchaudio.transforms.MelSpectrogram(\n    sample_rate=16000,\n    n_mels=128),\n        torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n        torchaudio.transforms.TimeMasking(time_mask_param=35)\n)\n\ntest_audio_transforms = nn.Sequential(\n        torchaudio.transforms.MelSpectrogram(\n          sample_rate=16000,\n           n_mels=128\n          ),\n\n)","metadata":{"id":"ZFSPjx7zY0H2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e853737-f39d-432f-8c0b-4cd6011d186b","execution":{"iopub.status.busy":"2023-03-27T15:17:00.989146Z","iopub.execute_input":"2023-03-27T15:17:00.989568Z","iopub.status.idle":"2023-03-27T15:17:01.213041Z","shell.execute_reply.started":"2023-03-27T15:17:00.989509Z","shell.execute_reply":"2023-03-27T15:17:01.212059Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"class Collate:\n    def __init__(self, data_type = 'test') -> None:\n        super(Collate, self).__init__() \n\n        self.data_type = data_type\n\n    def __call__(self, data: torchaudio.datasets.librispeech.LIBRISPEECH) -> Tuple[List[torch.Tensor], ...]:\n        \"\"\"\n        :param data: is a list of tuples of [features, label], where features has dimensions [n_features, length]\n        \"returns features, lengths, labels: \n              features is a Tensor [batchsize, features, max_length]\n              lengths is a Tensor of lengths [batchsize]\n              labels is a Tesnor of targets [batchsize]\n        \"\"\"\n\n        spectrograms = []\n        labels = []\n        input_lengths = []\n        label_lengths = []\n        for (waveform, _, utterance, _, _, _) in data:\n            if self.data_type == 'train':\n                spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n            elif self.data_type == 'test':\n                spec = test_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n            else:\n                raise Exception('data_type should be train or valid')\n            spectrograms.append(spec)\n            label = torch.Tensor(tokenizer.text_to_indices(utterance.lower()))\n            labels.append(label)\n            input_lengths.append(spec.shape[0] // 2)\n            label_lengths.append(len(label))\n\n        spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n        labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n\n        return spectrograms, labels, input_lengths, label_lengths\n","metadata":{"id":"noWmJGQe67IJ","execution":{"iopub.status.busy":"2023-03-27T15:17:01.215509Z","iopub.execute_input":"2023-03-27T15:17:01.216414Z","iopub.status.idle":"2023-03-27T15:17:01.226346Z","shell.execute_reply.started":"2023-03-27T15:17:01.216373Z","shell.execute_reply":"2023-03-27T15:17:01.225201Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Implement a Neural Network Model\n\nYou should try out a few different model types:\n- Feed-Forward Model (DNN)\n- Recurrent Model (GRU or LSTM)\n- Bidirectional Recurrent Model (bi-GRU or bi-LSTM)\n- Something different for bonus points\n\nBefore any of this models you can use convolutional layers, as shown in the example below\n\nAfter your experiments you should write a report with comparison of different models in terms of different features, for example: parameters, training speed, resulting quality, spectrogram properties, and data augmentations. Remember, that for full mark you need to achive good WER \n\nWER criterions: 60-50 -- 6 points, 50-40 -- 10 points, 40-35 -- 14 points, <= 35 -- 20 points","metadata":{"id":"kPYITlXT7AoG"}},{"cell_type":"code","source":"#!L\n\n# Our model classes are just examples, you can change them as you want\n\n# Define model\nclass CNNLayerNorm(nn.Module):\n    \"\"\"Layer normalization built for CNNs input\"\"\"\n\n    def __init__(self, n_feats: int) -> None:\n        super(CNNLayerNorm, self).__init__()\n        self.layer_norm = nn.LayerNorm(n_feats)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x (batch, channel, feature, time)\n        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n        x = self.layer_norm(x)\n        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n\n\nclass ResidualCNN(nn.Module):\n    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n        except with layer norm instead of batch norm\n    \"\"\"\n\n    def __init__(self, in_channels: int, out_channels: int, kernel: int, stride: int, dropout: float, n_feats: int) -> None:\n        super(ResidualCNN, self).__init__()\n\n\n        self.layer1 = nn.Sequential(CNNLayerNorm(n_feats),\n                                    nn.ReLU(),\n                                    nn.Dropout(dropout),\n                                    nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2),\n                                    )\n        \n        self.layer2 = nn.Sequential(CNNLayerNorm(n_feats),\n                            nn.ReLU(),\n                            nn.Dropout(dropout),\n                            nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2),\n                            )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        residual = x  # (batch, channel, feature, time)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x += residual\n        return x  # (batch, channel, feature, time)\n\n\nclass FeatureExtractor(nn.Module):\n\n    def __init__(self, n_cnn_layers: int, n_rnn_layers: int, rnn_dim: int,\n                 n_feats: int, stride: int = 2, dropout: float = 0.1) -> None:\n        super(FeatureExtractor, self).__init__()\n        n_feats = n_feats // 2\n        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n\n        # n residual cnn layers with filter size of 32\n        self.rescnn_layers = nn.Sequential(*[\n            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n            for _ in range(n_cnn_layers)\n        ])\n        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n      \n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.cnn(x)\n        x = self.rescnn_layers(x)\n        sizes = x.size()\n        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n        x = x.transpose(1, 2)  # (batch, time, feature)\n        x = self.fully_connected(x)\n        return x\n\nclass CTCDNN(nn.Module):\n\n    def __init__(self, n_cnn_layers: int, n_rnn_layers: int, rnn_dim: int, n_class: int, \n                 n_feats: int, stride: int = 2, dropout: float = 0.1) -> None:\n        super(CTCDNN, self).__init__()\n        \n        self.feature_extractor = FeatureExtractor(n_cnn_layers, n_rnn_layers, rnn_dim,\n                 n_feats, stride, dropout)\n        \n        self.intermediate_layers = nn.Sequential(nn.Linear(rnn_dim,rnn_dim//2),nn.ReLU(),\n                                                nn.Linear(rnn_dim//2,rnn_dim//4),nn.ReLU())\n\n        self.classifier = nn.Linear(rnn_dim//4, n_class)\n\n    def forward(self, x: torch.Tensor, input_lengths: torch.Tensor) -> torch.Tensor:\n            x = self.feature_extractor(x)\n            x = self.intermediate_layers(x)\n            x = self.classifier(x)\n            return x\n\nclass CTCRNN(nn.Module):\n\n    def __init__(self, n_cnn_layers: int, n_rnn_layers: int, rnn_dim: int, n_class: int, \n                 n_feats: int, stride: int = 2, dropout: float = 0.1,) -> None:\n        super(CTCRNN, self).__init__()\n\n        self.feature_extractor = FeatureExtractor(n_cnn_layers, n_rnn_layers, rnn_dim,\n                        n_feats, stride, dropout)\n\n        self.intermediate_layers = nn.GRU(input_size=rnn_dim, hidden_size=rnn_dim,\n                                          num_layers=n_rnn_layers,\n                                          bidirectional=False)\n        \n        self.act = nn.ReLU()\n\n        self.classifier = nn.Linear(rnn_dim, n_class)\n\n    def forward(self, x: torch.Tensor, input_lengths: torch.Tensor) -> torch.Tensor:\n            x = self.feature_extractor(x)\n            x, _ = self.intermediate_layers(x)\n            x = self.act(x)\n            x = self.classifier(x)\n            return x\n\n\nclass CTCBiRNN(nn.Module):\n\n    def __init__(self, n_cnn_layers: int, n_rnn_layers: int, rnn_dim: int, n_class: int, \n                 n_feats: int, stride: int = 2, dropout: float = 0.1) -> None:\n        super(CTCBiRNN, self).__init__()\n        \n        self.feature_extractor = FeatureExtractor(n_cnn_layers, n_rnn_layers, rnn_dim,\n                 n_feats, stride, dropout)\n\n        self.intermediate_layers = nn.GRU(input_size=rnn_dim, hidden_size=rnn_dim,\n                                          num_layers=n_rnn_layers,\n                                          bidirectional=True)\n        \n        self.act = nn.ReLU()\n\n        self.classifier = nn.Linear(2*rnn_dim, n_class)\n\n\n    def forward(self, x: torch.Tensor, input_lengths: torch.Tensor) -> torch.Tensor:\n            x = self.feature_extractor(x)\n            x, _ = self.intermediate_layers(x)\n            x = self.act(x)\n            x = self.classifier(x)\n            return x","metadata":{"id":"c1eUPtQ57EoX","execution":{"iopub.status.busy":"2023-03-27T18:45:38.517231Z","iopub.execute_input":"2023-03-27T18:45:38.517590Z","iopub.status.idle":"2023-03-27T18:45:38.550608Z","shell.execute_reply.started":"2023-03-27T18:45:38.517555Z","shell.execute_reply":"2023-03-27T18:45:38.548626Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Training and Evaluation Code","metadata":{"id":"fmzKVa497Tav"}},{"cell_type":"code","source":"#!L\n\ndef train(model: nn.Module, device: str, train_loader: data.DataLoader, \n          criterion: nn.Module, optimizer: torch.optim.Optimizer, \n          scheduler: torch.optim.lr_scheduler, epoch: int) -> None:\n    model.train()\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data\n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n        output = F.log_softmax(output, dim=2)\n        output = output.transpose(0, 1)  # (time, batch, n_class)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        if batch_idx % 100 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                       100. * batch_idx / len(train_loader), loss.item()))\n            wandb.log({'loss_train': loss.item()})\n\ndef test(model: nn.Module, device: str, test_loader: data.DataLoader, \n         criterion: nn.Module, epoch: int, decode: str = 'Greedy', lm: LanguageModel = None, save_path: str = None) -> None:\n    print('Beginning eval...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        start = time.time()\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data\n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n            \n            matrix = model(spectrograms, input_lengths)  # (batch, time, n_class)\n            matrix = F.log_softmax(matrix, dim=2)\n            probs = F.softmax(matrix,dim=2)\n            matrix = matrix.transpose(0, 1)  # (time, batch, n_class)\n                \n            if i == 3:\n                np.savetxt(f\"{save_path}_matrix.txt\", probs[0].cpu().numpy())\n                np.savetxt(f\"{save_path}_labels.txt\", labels[0].cpu().numpy())\n\n            loss = criterion(matrix, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n\n            if decode == 'Greedy':\n                decoded_preds, decoded_targets = greedy_decoder(matrix.transpose(0, 1), labels, label_lengths)\n            elif decode == 'BeamSearch':\n                ## THIS IS THE FUNCTION YOU SHOULD IMPLEMENT\n                decoded_preds, decoded_targets = beam_search_decoder(probs, labels, label_lengths, input_lengths, lm=lm)\n            for j in range(len(decoded_preds)):\n                test_cer.append(utils.cer(decoded_targets[j], decoded_preds[j]))\n                test_wer.append(utils.wer(decoded_targets[j], decoded_preds[j]))\n\n    avg_cer = sum(test_cer) / len(test_cer)\n    avg_wer = sum(test_wer) / len(test_wer)\n    wandb.log({'loss_test': test_loss, 'avg_cer': avg_cer, 'avg_wer': avg_wer})\n    print(\n        'Epoch: {:d}, Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(epoch, test_loss,\n                                                                                                       avg_cer,\n                                                                                                       avg_wer))","metadata":{"id":"v_O37QIX3nft","execution":{"iopub.status.busy":"2023-03-27T15:17:01.260929Z","iopub.execute_input":"2023-03-27T15:17:01.261496Z","iopub.status.idle":"2023-03-27T15:17:01.279824Z","shell.execute_reply.started":"2023-03-27T15:17:01.261458Z","shell.execute_reply":"2023-03-27T15:17:01.278776Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#!L\ntorch.manual_seed(7)\nif torch.cuda.is_available():\n    print('GPU found! 🎉')\n    device = 'cuda'\nelse:\n    print('Only CPU found! 💻')\n    device = 'cpu'\n\nverbose=False\n\n# Hyperparameters for your model\n\n\n\nhparams = {\n    \"n_cnn_layers\": 3,\n    \"n_rnn_layers\": 5,\n    \"rnn_dim\": 512,\n    \"n_class\": 29,\n    \"n_feats\": 128,\n    \"stride\": 2,\n    \"dropout\": 0.1,\n    \"learning_rate\": 3e-4,\n    \"batch_size\": 32,\n    \"epochs\": 10\n}\n\n\ntrain_collate_fn = Collate(data_type='train')\ntest_collate_fn = Collate(data_type='test')\n\n# Define Dataloyour training and test data loaders\nkwargs = {'num_workers': 2, 'pin_memory': True} if device == 'cuda' else {}\ntrain_loader = data.DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True, collate_fn=train_collate_fn, **kwargs)\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\ntest_loader = data.DataLoader(test_dataset, batch_size=hparams['batch_size'], shuffle=False, collate_fn=test_collate_fn, **kwargs)","metadata":{"id":"iO-mKLPt7Xhb","outputId":"5faa1ce6-233d-488f-d3c0-3d3a763d73be","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-03-27T15:17:01.281300Z","iopub.execute_input":"2023-03-27T15:17:01.281906Z","iopub.status.idle":"2023-03-27T15:17:01.368431Z","shell.execute_reply.started":"2023-03-27T15:17:01.281866Z","shell.execute_reply":"2023-03-27T15:17:01.367464Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"GPU found! 🎉\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We recommend to use \"Weights & Biases\" for experiment logging. See their [documentation](https://docs.wandb.ai/) for detais.","metadata":{"id":"q_uhuVgw2XbB","outputId":"5910f7ac-260c-4506-b910-500bc8dcd645"}},{"cell_type":"code","source":"wandb.init(project=\"hw2-dlaudio_1\", \n           group=\"DNN\",\n           config=hparams)","metadata":{"id":"3cVNk7KkY0H4","outputId":"f7a604fd-28d3-4f35-a32f-87b863cc979e","colab":{"base_uri":"https://localhost:8080/","height":213},"execution":{"iopub.status.busy":"2023-03-27T15:17:01.371677Z","iopub.execute_input":"2023-03-27T15:17:01.372359Z","iopub.status.idle":"2023-03-27T15:18:00.138542Z","shell.execute_reply.started":"2023-03-27T15:17:01.372320Z","shell.execute_reply":"2023-03-27T15:18:00.137267Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ····························\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 28\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.13.10"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230327_151728-ze2zbgzw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bidja/hw2-dlaudio_1/runs/ze2zbgzw' target=\"_blank\">wild-bird-3</a></strong> to <a href='https://wandb.ai/bidja/hw2-dlaudio_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bidja/hw2-dlaudio_1' target=\"_blank\">https://wandb.ai/bidja/hw2-dlaudio_1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bidja/hw2-dlaudio_1/runs/ze2zbgzw' target=\"_blank\">https://wandb.ai/bidja/hw2-dlaudio_1/runs/ze2zbgzw</a>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bidja/hw2-dlaudio_1/runs/ze2zbgzw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7f120a007cd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Compare different models: DNN, GRU/LSTM, bi-GRU/bi-LSTM (5 points)\n\nTrain and discuss differences in the different models. \n\nCompare performance of DNN, RNN and BiRNN models in terms of:\n-  WER / CER \n-  Training time\n-  Training stability \n-  Any other properties?","metadata":{"id":"gB79UDNM8UOZ"}},{"cell_type":"markdown","source":"**Не успел обучить полностью, так как модели тяжелые, а ресурсов недостаточно**\n\n**Сравнение по качеству на тестовой выборке.**\n\nНаилучшее качество показывает BiRNN. Сравнение производится для одиннадцатой эпохи каждого алгоритма (доучить все до максимального количества эпох не хватило ресурсов). \n\nBIRNN - WER: 0.4888, CER: 0.165\n\\\nRNN - WER: 0.657, CER:0.235\n\nDNN не показывает хорошего качества\n\n**Время обучения**\n\nBiRNN учится значительно дольше RNN  (примерно, на 40%). \nМодель с полносвязными слоями я сделал не слишком тяжелую (так как отствовали достаточные вычислительные ресурсы) и она работает значительно быстрее (примерно, в 4 раза быстрее, чем BiRNN).\n\n**Стабильность обучения**\n\nBiRNN в обучении менее стабильна, чем RNN. DNN ведет себя в процессе обучения также стабильно\n\n\n**Максимальное качество, которое мне удалось достичь - 0.45**","metadata":{}},{"cell_type":"code","source":"# utils.load_checkpoint(ctc_dnn, \"/kaggle/working/ctc_dnn_epoch2.tar\", \"/kaggle/working/ctc_dnn_epoch2.tar\", device)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T19:21:36.575402Z","iopub.execute_input":"2023-03-27T19:21:36.575810Z","iopub.status.idle":"2023-03-27T19:21:36.605221Z","shell.execute_reply.started":"2023-03-27T19:21:36.575773Z","shell.execute_reply":"2023-03-27T19:21:36.600546Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Train a non-recurrent model\nctc_dnn = CTCDNN(\n    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout'])\nctc_dnn.to(device)\n\n\noptimizer =optim.AdamW(ctc_dnn.parameters(), 3e-4)","metadata":{"id":"YJZH5l2YY0H5","execution":{"iopub.status.busy":"2023-03-27T19:14:44.244631Z","iopub.execute_input":"2023-03-27T19:14:44.245953Z","iopub.status.idle":"2023-03-27T19:20:52.626977Z","shell.execute_reply.started":"2023-03-27T19:14:44.245900Z","shell.execute_reply":"2023-03-27T19:20:52.619888Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CTCLoss(blank=tokenizer.get_symbol_index(BLANK_SYMBOL), reduction='mean')\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, steps_per_epoch=int(len(train_loader)),epochs=hparams['epochs'],anneal_strategy='linear')","metadata":{"id":"YJZH5l2YY0H5","execution":{"iopub.status.busy":"2023-03-27T19:14:44.244631Z","iopub.execute_input":"2023-03-27T19:14:44.245953Z","iopub.status.idle":"2023-03-27T19:20:52.626977Z","shell.execute_reply.started":"2023-03-27T19:14:44.245900Z","shell.execute_reply":"2023-03-27T19:20:52.619888Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Обученная модель не сохранилась, поэтому логи вывести не смог. Тем не менее, сходимость и качество финального решения сильно уступает аналогам**","metadata":{}},{"cell_type":"code","source":"#\nfor epoch in tqdm(range(1, hparams['epochs'] -4)):\n    train(ctc_dnn, device, train_loader, criterion, optimizer, scheduler, epoch)\n#     utils.save_checkpoint(ctc_dnn, checkpoint_name=f'ctc_dnn_epoch{epoch}.tar')\n    wandb.save(f'ctc_dnn_epoch{epoch}.tar')\n    test(ctc_dnn, device, test_loader, criterion, epoch, 'Greedy')\n\nutils.save_checkpoint(ctc_dnn, checkpoint_name=f'ctc_dnn.tar')","metadata":{"id":"YJZH5l2YY0H5","execution":{"iopub.status.busy":"2023-03-27T20:02:26.891003Z","iopub.execute_input":"2023-03-27T20:02:26.891740Z","iopub.status.idle":"2023-03-27T20:03:53.414401Z","shell.execute_reply.started":"2023-03-27T20:02:26.891687Z","shell.execute_reply":"2023-03-27T20:03:53.410702Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d736f5112d82441185d1d562aece2141"}},"metadata":{}},{"name":"stdout","text":"Train Epoch: 1 [0/28539 (0%)]\tLoss: 1.922668\nTrain Epoch: 1 [2000/28539 (7%)]\tLoss: 1.839648\nTrain Epoch: 1 [4000/28539 (14%)]\tLoss: 1.767055\nTrain Epoch: 1 [6000/28539 (21%)]\tLoss: 1.838558\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1672993741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_dnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     utils.save_checkpoint(ctc_dnn, checkpoint_name=f'ctc_dnn_epoch{epoch}.tar')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ctc_dnn_epoch{epoch}.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_dnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Greedy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1653807821.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Train a  recurrent model\nctc_rnn = CTCRNN(\n    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n).to(device)","metadata":{"id":"EnjLgyVrWq83","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e3a09bf9e5c2489d8ac8989f6a0904dd","ca1a0f3f22cd4907b5b2abf891783ed5","520a77acd09b43fdb6167f312b1695e4","7b14d1d50416401588904444d26a0b1a","d789b389030e451aa59f346cf2a6a6b2","73149239d2f54a4581b03bda95f0af1c","41b358772ba44b42b87c0e6c91793348","773a434795d3403cb8c7ccfb0fe5833d","4ac15917a5c541e1bbe584ca5855b9f9","496bd08c960e46fd8047ff076932dc9b","b1f02a4b976e4638bff87944d454ba5c"]},"outputId":"146132f0-a190-4dda-d9b2-550ea86b938d","execution":{"iopub.status.busy":"2023-03-27T15:18:00.159123Z","iopub.execute_input":"2023-03-27T15:18:00.159844Z","iopub.status.idle":"2023-03-27T15:29:16.315180Z","shell.execute_reply.started":"2023-03-27T15:18:00.159805Z","shell.execute_reply":"2023-03-27T15:29:16.313376Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(ctc_rnn.parameters(), 3e-4)\ncriterion = nn.CTCLoss(blank=tokenizer.get_symbol_index(BLANK_SYMBOL), reduction='mean')\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4,steps_per_epoch=int(len(train_loader)),epochs=hparams['epochs'],anneal_strategy='linear')","metadata":{"id":"EnjLgyVrWq83","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e3a09bf9e5c2489d8ac8989f6a0904dd","ca1a0f3f22cd4907b5b2abf891783ed5","520a77acd09b43fdb6167f312b1695e4","7b14d1d50416401588904444d26a0b1a","d789b389030e451aa59f346cf2a6a6b2","73149239d2f54a4581b03bda95f0af1c","41b358772ba44b42b87c0e6c91793348","773a434795d3403cb8c7ccfb0fe5833d","4ac15917a5c541e1bbe584ca5855b9f9","496bd08c960e46fd8047ff076932dc9b","b1f02a4b976e4638bff87944d454ba5c"]},"outputId":"146132f0-a190-4dda-d9b2-550ea86b938d","execution":{"iopub.status.busy":"2023-03-27T15:18:00.159123Z","iopub.execute_input":"2023-03-27T15:18:00.159844Z","iopub.status.idle":"2023-03-27T15:29:16.315180Z","shell.execute_reply.started":"2023-03-27T15:18:00.159805Z","shell.execute_reply":"2023-03-27T15:29:16.313376Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**В следующей ячейке вывожу качество, достигнутое на 11 эпохе**","metadata":{}},{"cell_type":"code","source":"#test evaluation on 11 epoch\ntest(ctc_rnn, device, test_loader, criterion, epoch, 'Greedy')","metadata":{"execution":{"iopub.status.busy":"2023-03-27T19:51:40.487644Z","iopub.execute_input":"2023-03-27T19:51:40.488771Z","iopub.status.idle":"2023-03-27T19:57:56.531072Z","shell.execute_reply.started":"2023-03-27T19:51:40.488713Z","shell.execute_reply":"2023-03-27T19:57:56.527938Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Beginning eval...\nEpoch: 11, Test set: Average loss: 0.7741, Average CER: 0.235237 Average WER: 0.6570\n\n","output_type":"stream"}]},{"cell_type":"code","source":"scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\nfor epoch in tqdm(range(11,12)):\n    train(ctc_rnn, device, train_loader, criterion, optimizer, scheduler, epoch)\n    utils.save_checkpoint(ctc_rnn, checkpoint_name=f'ctc_rnn_epoch{epoch}.tar')\n    wandb.save(f'ctc_rnn_epoch{epoch}.tar')\n    test(ctc_rnn, device, test_loader, criterion, epoch, 'Greedy')\n\nutils.save_checkpoint(ctc_rnn, checkpoint_name=f'ctc_rnn.tar')","metadata":{"id":"EnjLgyVrWq83","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e3a09bf9e5c2489d8ac8989f6a0904dd","ca1a0f3f22cd4907b5b2abf891783ed5","520a77acd09b43fdb6167f312b1695e4","7b14d1d50416401588904444d26a0b1a","d789b389030e451aa59f346cf2a6a6b2","73149239d2f54a4581b03bda95f0af1c","41b358772ba44b42b87c0e6c91793348","773a434795d3403cb8c7ccfb0fe5833d","4ac15917a5c541e1bbe584ca5855b9f9","496bd08c960e46fd8047ff076932dc9b","b1f02a4b976e4638bff87944d454ba5c"]},"outputId":"146132f0-a190-4dda-d9b2-550ea86b938d","execution":{"iopub.status.busy":"2023-03-27T19:35:19.264939Z","iopub.execute_input":"2023-03-27T19:35:19.266193Z","iopub.status.idle":"2023-03-27T19:50:29.966121Z","shell.execute_reply.started":"2023-03-27T19:35:19.266131Z","shell.execute_reply":"2023-03-27T19:50:29.962744Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90cf1675b5c4e10b1032b1e48876f35"}},"metadata":{}},{"name":"stdout","text":"Train Epoch: 11 [0/28539 (0%)]\tLoss: 0.777918\nTrain Epoch: 11 [2000/28539 (7%)]\tLoss: 0.805927\nTrain Epoch: 11 [4000/28539 (14%)]\tLoss: 0.845940\nTrain Epoch: 11 [6000/28539 (21%)]\tLoss: 0.848871\nTrain Epoch: 11 [8000/28539 (28%)]\tLoss: 0.766545\nTrain Epoch: 11 [10000/28539 (35%)]\tLoss: 0.789375\nTrain Epoch: 11 [12000/28539 (42%)]\tLoss: 0.798177\nTrain Epoch: 11 [14000/28539 (49%)]\tLoss: 0.808786\nTrain Epoch: 11 [16000/28539 (56%)]\tLoss: 0.778209\nTrain Epoch: 11 [18000/28539 (63%)]\tLoss: 0.760599\nTrain Epoch: 11 [20000/28539 (70%)]\tLoss: 0.778888\nTrain Epoch: 11 [22000/28539 (77%)]\tLoss: 0.761369\nTrain Epoch: 11 [24000/28539 (84%)]\tLoss: 0.722780\nTrain Epoch: 11 [26000/28539 (91%)]\tLoss: 0.832596\nTrain Epoch: 11 [28000/28539 (98%)]\tLoss: 0.755780\nBeginning eval...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3655145162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'ctc_rnn_epoch{epoch}.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ctc_rnn_epoch{epoch}.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Greedy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'ctc_rnn.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1653807821.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, criterion, epoch, decode, lm, save_path)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mtest_cer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mtest_wer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/current/utils.py\u001b[0m in \u001b[0;36mcer\u001b[0;34m(reference, hypothesis, ignore_case, remove_space)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n\u001b[0;32m---> 33\u001b[0;31m                                          remove_space)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mref_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/current/utils.py\u001b[0m in \u001b[0;36mchar_errors\u001b[0;34m(reference, hypothesis, ignore_case, remove_space)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0medit_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_levenshtein_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medit_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/current/utils.py\u001b[0m in \u001b[0;36m_levenshtein_distance\u001b[0;34m(ref, hyp)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0ms_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mi_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0md_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_row_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"ctc_birnn = CTCBiRNN(\n    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n).to(device)","metadata":{"id":"HlXDQ1bkYn4f","execution":{"iopub.status.busy":"2023-03-27T19:57:56.533599Z","iopub.execute_input":"2023-03-27T19:57:56.534343Z","iopub.status.idle":"2023-03-27T19:57:56.778508Z","shell.execute_reply.started":"2023-03-27T19:57:56.534294Z","shell.execute_reply":"2023-03-27T19:57:56.776485Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# utils.load_checkpoint(ctc_birnn, \"/kaggle/input/birnncheckpoint/ctc_birnn_epoch11.tar\", \"/kaggle/input/birnncheckpoint/ctc_birnn_epoch11.tar\", device)","metadata":{"id":"DmrxmulBbZj2","execution":{"iopub.status.busy":"2023-03-27T19:57:56.779774Z","iopub.execute_input":"2023-03-27T19:57:56.780174Z","iopub.status.idle":"2023-03-27T19:57:56.882587Z","shell.execute_reply.started":"2023-03-27T19:57:56.780115Z","shell.execute_reply":"2023-03-27T19:57:56.881443Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Train a  recurrent model\noptimizer = optim.AdamW(ctc_birnn.parameters(), 3e-4)","metadata":{"id":"B4ylbT6eWqx_","colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["31260ed6c1f744d5b7c158cbca479e88","066d73f036a045e68be9478e9ea13399","e306fe3156564bb0b34d3935e489a4c3","59093bb8053445749de2219fa722866d","df033e0d358d4ffaa1da1f3c941407e8","bbc4330051994a02a9cdf5b9a27c337b","328fec4bbd544fda96a6b126cc553b51","6a79a9ec2e8a407284ae17bb3af9fa58","8e7c0fa474ed4772a731f6240e3c42dd","70d47ce411cc48c1b52003a2a1c33862","a14c404da4b946b1b02c131a50d8e460"]},"outputId":"35dbef57-2ccb-48f6-c655-b95c0e6b0d68","execution":{"iopub.status.busy":"2023-03-27T20:04:06.180274Z","iopub.execute_input":"2023-03-27T20:04:06.181418Z","iopub.status.idle":"2023-03-27T20:04:06.190021Z","shell.execute_reply.started":"2023-03-27T20:04:06.181375Z","shell.execute_reply":"2023-03-27T20:04:06.188986Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"**Часто загружал веса, поэтому вывожу только последние логи 12 эпохи**\n**В архиве прилагаю скрины логов предыдущих нескольких эпох** (Колаб отрубает соединение, если долго учить)","metadata":{}},{"cell_type":"code","source":"\ncriterion = nn.CTCLoss(blank=tokenizer.get_symbol_index(BLANK_SYMBOL), reduction='mean')\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4,steps_per_epoch=int(len(train_loader)),epochs=hparams['epochs'],anneal_strategy='linear')\n\nfor epoch in tqdm(range(1, 15)):\n    train(ctc_birnn, device, train_loader, criterion, optimizer, scheduler, epoch)\n    utils.save_checkpoint(ctc_birnn, checkpoint_name=f'ctc_birnn_epoch{epoch}.tar')\n    wandb.save(f'ctc_birnn_epoch{epoch}.tar')\n    test(ctc_birnn, device, test_loader, criterion, epoch, 'Greedy')\n\nutils.save_checkpoint(ctc_birnn, checkpoint_name=f'ctc_birnn.tar')","metadata":{"id":"B4ylbT6eWqx_","colab":{"base_uri":"https://localhost:8080/","height":431,"referenced_widgets":["31260ed6c1f744d5b7c158cbca479e88","066d73f036a045e68be9478e9ea13399","e306fe3156564bb0b34d3935e489a4c3","59093bb8053445749de2219fa722866d","df033e0d358d4ffaa1da1f3c941407e8","bbc4330051994a02a9cdf5b9a27c337b","328fec4bbd544fda96a6b126cc553b51","6a79a9ec2e8a407284ae17bb3af9fa58","8e7c0fa474ed4772a731f6240e3c42dd","70d47ce411cc48c1b52003a2a1c33862","a14c404da4b946b1b02c131a50d8e460"]},"outputId":"35dbef57-2ccb-48f6-c655-b95c0e6b0d68","execution":{"iopub.status.busy":"2023-03-27T20:04:06.339605Z","iopub.execute_input":"2023-03-27T20:04:06.339961Z","iopub.status.idle":"2023-03-27T20:37:03.205335Z","shell.execute_reply.started":"2023-03-27T20:04:06.339930Z","shell.execute_reply":"2023-03-27T20:37:03.202282Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ceb29409ad4a5d9fddaec0772f2da0"}},"metadata":{}},{"name":"stdout","text":"Train Epoch: 1 [0/28539 (0%)]\tLoss: 0.512159\nTrain Epoch: 1 [2000/28539 (7%)]\tLoss: 0.421642\nTrain Epoch: 1 [4000/28539 (14%)]\tLoss: 0.450554\nTrain Epoch: 1 [6000/28539 (21%)]\tLoss: 0.503061\nTrain Epoch: 1 [8000/28539 (28%)]\tLoss: 0.492165\nTrain Epoch: 1 [10000/28539 (35%)]\tLoss: 0.418610\nTrain Epoch: 1 [12000/28539 (42%)]\tLoss: 0.491654\nTrain Epoch: 1 [14000/28539 (49%)]\tLoss: 0.436879\nTrain Epoch: 1 [16000/28539 (56%)]\tLoss: 0.511172\nTrain Epoch: 1 [18000/28539 (63%)]\tLoss: 0.511531\nTrain Epoch: 1 [20000/28539 (70%)]\tLoss: 0.503847\nTrain Epoch: 1 [22000/28539 (77%)]\tLoss: 0.441460\nTrain Epoch: 1 [24000/28539 (84%)]\tLoss: 0.508370\nTrain Epoch: 1 [26000/28539 (91%)]\tLoss: 0.525610\nTrain Epoch: 1 [28000/28539 (98%)]\tLoss: 0.456264\nBeginning eval...\nEpoch: 1, Test set: Average loss: 0.5397, Average CER: 0.156743 Average WER: 0.4669\n\nTrain Epoch: 2 [0/28539 (0%)]\tLoss: 0.444022\nTrain Epoch: 2 [2000/28539 (7%)]\tLoss: 0.450606\nTrain Epoch: 2 [4000/28539 (14%)]\tLoss: 0.454099\nTrain Epoch: 2 [6000/28539 (21%)]\tLoss: 0.466555\nTrain Epoch: 2 [8000/28539 (28%)]\tLoss: 0.473770\nTrain Epoch: 2 [10000/28539 (35%)]\tLoss: 0.460338\nTrain Epoch: 2 [12000/28539 (42%)]\tLoss: 0.626134\nTrain Epoch: 2 [14000/28539 (49%)]\tLoss: 0.414745\nTrain Epoch: 2 [16000/28539 (56%)]\tLoss: 0.518017\nTrain Epoch: 2 [18000/28539 (63%)]\tLoss: 0.569254\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2282055286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_birnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctc_birnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'ctc_birnn_epoch{epoch}.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ctc_birnn_epoch{epoch}.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1653807821.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}