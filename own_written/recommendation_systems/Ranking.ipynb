{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6577c365",
   "metadata": {},
   "source": [
    "# Домашнаяя работа №2. \n",
    "# Автор: Серегин М. С"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81172682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b9078",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6714540",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c999b2a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MAP(ranked_arr, true_rel, n):\n",
    "    \"\"\"\n",
    "    На вход подается отранжированный массив индексов и массив релевантности каждого элемента по порядку. \n",
    "    Example of input:\n",
    "        ranked_arr = [[2,3,1,0],\n",
    "                      [1,0,2,4]]\n",
    "                      \n",
    "        true_rel   = [[0,0,1,0,1,1,1],\n",
    "                        [0,0,1,1,1,1]]\n",
    "    \"\"\"\n",
    "    \n",
    "    def precision_k(ranked_arr, true_rel, k):\n",
    "\n",
    "        ind = ranked_arr[:,:k]\n",
    "        rels = np.take_along_axis(true_rel, ind, axis=1) != 0 \n",
    "        return np.mean(rels, axis=1)\n",
    "    \n",
    "    def avg_precision_n(ranked_arr, true_rel, n):\n",
    "\n",
    "        sum_precision_n = np.zeros(ranked_arr.shape[0])\n",
    "        m = min(n, ranked_arr.shape[1])\n",
    "        for k in range(1,m+1):\n",
    "            arr_precision = precision_k(ranked_arr, true_rel, k)\n",
    "            ind = ranked_arr[:,k-1].reshape(-1,1)  \n",
    "            rel_exact_k = np.take_along_axis(true_rel, ind, axis=1).reshape(-1) != 0\n",
    "            out = rel_exact_k * arr_precision\n",
    "            sum_precision_n += out\n",
    "\n",
    "        return sum_precision_n / m\n",
    "        \n",
    "        \n",
    "    return np.mean(avg_precision_n(ranked_arr, true_rel, n))\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529c2b36",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_MAP():\n",
    "    \n",
    "    ranked_arr = np.array([[2,3,1,0],\n",
    "                          [1,0,2,4]])\n",
    "    true_rel   = np.array([[0,0,1,0,1,1],\n",
    "                    [0,0,1,1,1,1]])\n",
    "    \n",
    "    assert np.abs(MAP(ranked_arr, true_rel, 1) - 0.5) < 0.001\n",
    "    assert np.abs(MAP(ranked_arr, true_rel, 2) - 0.25) < 0.001\n",
    "    assert np.abs(MAP(ranked_arr, true_rel, 3) - 0.222) < 0.001\n",
    "    assert np.abs(MAP(ranked_arr, true_rel, 4) - 0.229) < 0.001\n",
    "    \n",
    "test_MAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d604cd1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9135cfde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MRR(ranked_arr, true_rel):\n",
    "    \"\"\"\n",
    "    На вход подается отранжированный массив индексов и массив релевантности каждого элемента по порядку. \n",
    "    Example of input:\n",
    "    ranked_arr = np.array([[2,3,1,0],\n",
    "              [1,0,2,4]])\n",
    "    true_rel   = np.array([[0,0,1,0,1,1],\n",
    "                    [0,0,1,1,1,1]])\n",
    "    \"\"\"\n",
    "        \n",
    "    zero = np.zeros(ranked_arr.shape[0]) -1\n",
    "    ax_0, ax_1 = np.where(np.take_along_axis(true_rel, ranked_arr, axis=1) !=0) # релевантный , если != 0\n",
    "\n",
    "    for par in zip(ax_0, ax_1):\n",
    "        if zero[par[0]] == -1:\n",
    "            zero[par[0]] = par[1] + 1\n",
    "            \n",
    "\n",
    "            \n",
    "    return  np.sum(1 / zero[zero > 0]) / ranked_arr.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7af379",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def testMRR():\n",
    "    ranked_arr = np.array([[2,3,1,0],\n",
    "                            [1,0,2,4],\n",
    "                            [2,1,0,3],\n",
    "                            [2,3,0,1]])\n",
    "    \n",
    "    true_rel   = np.array([[0,0,1,0,1,1],\n",
    "                            [0,0,1,1,1,1],\n",
    "                          [0,1,0,1,1,1],\n",
    "                          [0,0,0,0,0,0]])\n",
    "    assert np.abs(MRR(ranked_arr, true_rel) - 0.458) < 0.001\n",
    "testMRR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9de695",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f85076",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def NDCG(ranked_arr, true_rel, n):\n",
    "    \"\"\"\n",
    "    Расчитывает метрику как для одного вектора, так и для нескольких, объединенных в массив. \n",
    "    В любом случае, размерность входных массивов = 2. \n",
    "    \"\"\"\n",
    "    \n",
    "    def DCG(ranked_arr, true_rel, n):\n",
    "        ind = 2**np.take_along_axis(true_rel, ranked_arr[:,:n], axis=1) - 1\n",
    "        log = np.log(np.arange(2,ind.shape[1]+2)) \n",
    "      \n",
    "        res = ind / log\n",
    "        return np.sum(res,axis=1)\n",
    "    \n",
    "    def IDCG(ranked_arr, true_rel, n):\n",
    "        k = min(ranked_arr.shape[1],n)\n",
    "        return np.sum(\n",
    "            (2**np.sort(true_rel,axis=1)[:,-1:-k-1:-1]-1) / np.log(np.arange(2,k+2)),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "    dcg = DCG(ranked_arr, true_rel, n)\n",
    "    idcg = IDCG(ranked_arr, true_rel, n)\n",
    "\n",
    "    return dcg / idcg\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89fa0ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# тестирование\n",
    "r = np.array([[3,2,3,0,1,2]])\n",
    "o = np.array([[0,1,2,3,4,5]])\n",
    "assert (NDCG(o,r,5) - np.array([0.875,])).sum() < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab2816",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b6bff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70ee720",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LambdaRank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feda8cc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LambdaRank:\n",
    "    def __init__(self,lr=0.1, sigma=1, num_epochs=3, seed=1, metric=NDCG,reg=0.05):\n",
    "\n",
    "        self.reg=reg\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.reg = 0.05\n",
    "        self.num_epochs = num_epochs\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit(self,df):\n",
    "        \"\"\"\n",
    "        На вход принимает pd.DataFrame, который имеет следующие столбцы: relevance, qid, *range(0,n). \n",
    "        n - количество признаков\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(df.columns) - 2\n",
    "        w = np.random.randn(1,n) \n",
    "\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            mistakes = 0\n",
    "            k = 0\n",
    "            for qid in df.qid.unique():\n",
    "                current_df = df[df.qid == qid].sort_values(\"relevance\", ascending=False).copy()\n",
    "\n",
    "                arr_relevance = np.array(current_df.relevance)\n",
    "                F = current_df.drop([\"relevance\", \"qid\"],axis=1).to_numpy()\n",
    "\n",
    "                arr_values = (w @ F.T).reshape(-1)\n",
    "                \n",
    "                zero = np.zeros(len(arr_values)).astype(np.int32)  \n",
    "                for pos, i in enumerate(np.argsort(-arr_values)):\n",
    "                    zero[i] = pos\n",
    "\n",
    "                # берем случайную пару и делаем шаг\n",
    "                \n",
    "                for i in range(len(current_df)): # n\n",
    "                    n_1, n_2 = np.sort(np.random.choice(range(len(current_df)), 2, replace=False)) # объекты в датасете отсортированы!\n",
    "                    \n",
    "              \n",
    "                    \n",
    "                    x1, x2 = F[n_1], F[n_2]\n",
    "                    r1, r2 = int(arr_relevance[n_1]), int(arr_relevance[n_2])\n",
    "                    o1,o2  = int(zero[n_1]), int(zero[n_2])\n",
    "                    \n",
    "\n",
    "                    assert (type(r1) == int) and (type(o1) == int) \n",
    "                    assert (type(r2) == int) and (type(o2) == int) \n",
    "\n",
    "                    \n",
    "                    o1 += 1\n",
    "                    o2 += 1 # так как при сортировке начинается с 0\n",
    "                    \n",
    "                    res1 = float(w@(x1-x2)) \n",
    "                    if r1 > r2 and res1 < 0:\n",
    "                        mistakes += 1\n",
    "\n",
    "                    if r1 > r2:\n",
    "                        k+=1\n",
    "                        delta_NDCG = np.abs((r1 / np.log(1 + o1) + r2 / np.log(1 + o2)) - (r1 / np.log(1 + o2) + r2 / np.log(1 + o1)))\n",
    "                        w = w + self.lr * self.sigma / (1 + np.exp(self.sigma * float(w@(x1-x2)))) * delta_NDCG * (x1 - x2).reshape(w.shape) \n",
    "\n",
    "                        assert res1 <= float(w@(x1-x2))\n",
    "\n",
    "\n",
    "\n",
    "        # trainig is completed   \n",
    "        self.w = w\n",
    "        \n",
    "        \n",
    "    def compute_metric_for_all_queries(self,df_val, n,metric=NDCG):\n",
    "        lst_metric = []\n",
    "        for qid_ in df_val.qid.unique():\n",
    "            current_df = df_val[df_val.qid == qid_]\n",
    "            \n",
    "            arr_relevance = np.array(current_df.relevance).reshape(1,-1)\n",
    "            F = current_df.drop([\"relevance\", \"qid\"],axis=1).to_numpy()\n",
    "            \n",
    "            order = np.argsort(-(self.w @ F.T).reshape(1,-1))\n",
    "\n",
    "\n",
    "            if (arr_relevance!=0).sum()>1: # исключаем те порядки, где нет ни одного релевантного - любой порядок будет эквивалентен\n",
    "\n",
    "                exact_metric = metric(order, arr_relevance,n) if metric is NDCG or metric is MAP else (\n",
    "                                                                                metric(order, arr_relevance))\n",
    "\n",
    "                lst_metric.append(float(exact_metric))\n",
    "\n",
    "        return np.array(lst_metric)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c21bef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c45d2d62",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test LambdaRank on MQ2007, MQ2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154e4d39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset_MQ2007 = pd.DataFrame([])\n",
    "for s in [\"S1.txt\",\"S2.txt\",\"S3.txt\",\"S4.txt\"]:\n",
    "    df = pd.read_csv(s, sep=\" \",names=range(57)).drop(labels=list(range(48,57)),axis=1)\n",
    "    df = df.replace(r'^.+:', '', regex=True)\n",
    "    df.columns = [\"relevance\", \"qid\",*list(range(46))]\n",
    "    df[[\"relevance\", \"qid\"]] = df[[\"relevance\", \"qid\"]].astype(np.int32)\n",
    "    df[[*list(range(46))]] = df[[*list(range(46))]].astype(np.float32)\n",
    "    \n",
    "    train_dataset_MQ2007 = pd.concat((train_dataset_MQ2007,df))\n",
    "    \n",
    "\n",
    "# val_dataset\n",
    "for s in [\"S5.txt\",]:\n",
    "    df = pd.read_csv(s, sep=\" \",names=range(57)).drop(labels=list(range(48,57)),axis=1)\n",
    "    df = df.replace(r'^.+:', '', regex=True)\n",
    "    df.columns = [\"relevance\", \"qid\",*list(range(46))]\n",
    "    df[[\"relevance\", \"qid\"]] = df[[\"relevance\", \"qid\"]].astype(np.int32)\n",
    "    df[[*list(range(46))]] = df[[*list(range(46))]].astype(np.float32)\n",
    "    \n",
    "    val_datasetMQ2007 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ee6cb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset_MQ2008 = pd.DataFrame([])\n",
    "for s in [\"S1.txt\",\"S2.txt\",\"S3.txt\",\"S4.txt\"]:\n",
    "    df = pd.read_csv(\"MQ2008/\" +s , sep=\" \",names=range(57)).drop(labels=list(range(48,57)),axis=1)\n",
    "    df = df.replace(r'^.+:', '', regex=True)\n",
    "    df.columns = [\"relevance\", \"qid\",*list(range(46))]\n",
    "    df[[\"relevance\", \"qid\"]] = df[[\"relevance\", \"qid\"]].astype(np.int32)\n",
    "    df[[*list(range(46))]] = df[[*list(range(46))]].astype(np.float32)\n",
    "    \n",
    "    train_dataset_MQ2008 = pd.concat((train_dataset_MQ2008,df))\n",
    "    \n",
    "\n",
    "# val_dataset\n",
    "for s in [\"S5.txt\",]:\n",
    "    df = pd.read_csv(\"MQ2008/\" +  s, sep=\" \",names=range(57)).drop(labels=list(range(48,57)),axis=1)\n",
    "    df = df.replace(r'^.+:', '', regex=True)\n",
    "    df.columns = [\"relevance\", \"qid\",*list(range(46))]\n",
    "    df[[\"relevance\", \"qid\"]] = df[[\"relevance\", \"qid\"]].astype(np.int32)\n",
    "    df[[*list(range(46))]] = df[[*list(range(46))]].astype(np.float32)\n",
    "    \n",
    "    val_datasetMQ2008 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d252a6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### MQ2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "68b9aa69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Lambdarank = LambdaRank(lr=0.01,\n",
    "    sigma=1,\n",
    "    num_epochs=10,\n",
    "    seed=1,\n",
    "    reg=0)\n",
    "Lambdarank2.fit(train_dataset_MQ2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "de6d6ad3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний NDCG@3 0.6495358772970298\n",
      "Средний NDCG@5 0.7120044380013448\n",
      "Средний NDCG@10 0.7707059361165118\n",
      "Средний NDCG@15 0.7815778766635076\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "for n in [3,5,10,15]:\n",
    "    res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2008,n,NDCG)\n",
    "    print(f\"Средний NDCG@{n}\", np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "72467d01",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний MRR 0.8695512820512821\n"
     ]
    }
   ],
   "source": [
    "#MRR\n",
    "res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2008,n,MRR)\n",
    "print(f\"Средний MRR\", np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "7eb39da2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний MAP@1 0.5945945945945946\n",
      "Средний MAP@2 0.5463320463320464\n",
      "Средний MAP@3 0.5053625053625053\n",
      "Средний MAP@4 0.4873712998712999\n"
     ]
    }
   ],
   "source": [
    "# MAP\n",
    "for n in [1,2,3,4]:\n",
    "    res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2007,n,MAP)\n",
    "    print(f\"Средний MAP@{n}\", np.mean(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759e74b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### MQ2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "id": "cef7a234",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Lambdarank = LambdaRank(lr=0.01,\n",
    "    sigma=1,\n",
    "    num_epochs=10,\n",
    "    seed=10,\n",
    "    reg=0)\n",
    "\n",
    "Lambdarank2.fit(train_dataset_MQ2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "cfe1a0be",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний NDCG@1 0.5546975546975548\n",
      "Средний NDCG@3 0.5332435869100559\n",
      "Средний NDCG@5 0.5324426825383389\n",
      "Средний NDCG@10 0.5586352284219644\n",
      "Средний NDCG@15 0.5925793844450021\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "for n in [3,5,10,15]:\n",
    "    res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2007,n,NDCG)\n",
    "    print(f\"Средний NDCG@{n}\", np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "id": "b15613e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний MRR 0.7174852457415483\n"
     ]
    }
   ],
   "source": [
    "#MRR\n",
    "res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2007,10,MRR)\n",
    "print(f\"Средний MRR\", np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "id": "56029dfb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний MAP@1 0.637065637065637\n",
      "Средний MAP@2 0.5801158301158301\n",
      "Средний MAP@3 0.5373230373230374\n",
      "Средний MAP@4 0.5043436293436293\n"
     ]
    }
   ],
   "source": [
    "# MAP\n",
    "for n in [1,2,3,4]:\n",
    "    res = Lambdarank.compute_metric_for_all_queries(val_datasetMQ2007,n,MAP)\n",
    "    print(f\"Средний MAP@{n}\", np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640856ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f201d463",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Подготовка обучающего и валидационного датасета \n",
    "# (датасет Movielens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f8083d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### В данном блоке мы сконструируем два датасета. \n",
    "#### Из тренировочного датасета будут исключены все тройки (user,item,rating), которые используются в валидации. \n",
    "#### Каждому пользователю, купившему хотя бы 70 товаров сопоставляется валидационный датасет, который необходимо отранжировать. На этих данных будет замеряться качество модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac31d5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## ? Как адаптировать датасет для ранжирования к задаче рекомендаций?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64693f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для каждого запроса нам дана релевантность. \n",
    "Можно составить матрицу R, где по строчкам будут отражены конкретные запросы, по столбцам все возможные документы. На пересечении столбца j и строчки i будет стоять релевантность документа j запросу i , если имеется и NAN в противном случае. \n",
    "Данная матрица может использоваться в качестве обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d59a84",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В исходном датасете имеются оценки 5,4,...1. \n",
    "Переведем их в соответствующие оценки, отражающие релевантность предмета. \\\n",
    "5 -> 1 \\\n",
    "4 -> 0.5 \\\n",
    "3 -> 0\\\n",
    "2 -> 0 \\\n",
    "1 -> 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "a6366852",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pivot_to_df(pivot_, user, item, rating):\n",
    "    \"\"\"\n",
    "    Функция по поданной сводной таблице строит pandas.DataFrame. \n",
    "    Вход: сводная таблица, например \n",
    "    >>> data = Dataset.load_builtin('ml-100k')\n",
    "    Выход: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    pivot = pivot_.copy()\n",
    "    pivot[user] = pivot[user].astype(int)\n",
    "    pivot[item] = pivot[item].astype(int)\n",
    "    pivot[rating] = pivot[rating].astype(int)\n",
    "\n",
    "    new_df = pd.DataFrame(index=range(1, max(pivot[user])+1), columns=range(1, max(pivot[item])+1))\n",
    "\n",
    "    for i in pivot.index:\n",
    "        curuser, curitem, currating = pivot.loc[i]\n",
    "\n",
    "        new_df.loc[curuser,curitem] = currating\n",
    "\n",
    "        \n",
    "    return new_df \n",
    "\n",
    "\n",
    "def compute_ml():\n",
    "    dataml = Dataset.load_builtin(\"ml-100k\")\n",
    "    ml = pd.DataFrame(dataml.raw_ratings)\n",
    "    ml.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "    ml.user = ml.user.astype(np.int32)\n",
    "    ml.item = ml.item.astype(np.int32)\n",
    "    ml.rating = ml.rating.astype(np.int32)\n",
    "    del ml[\"timestamp\"]\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "0b54c998",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ml =compute_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "4771345a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq_u = pd.DataFrame(ml.groupby(by=\"user\")[\"user\"].count()) # находим тех пользователей, которые купили, как минимум, 70 предметов.\n",
    "\n",
    "idx = np.array(freq_u[\"user\"] > 70) # 446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "9879faf1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_in_val = np.array(freq_u[idx].index) # 446 * len of ranking list=15 => валидационная выборка равна 6690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "cbbee893",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# для каждого пользователя из users_in_val добавим случайные 15 предметов в валидационный датасет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "972877d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У этого пользователя много нерелевантных объектов 102\n",
      "У этого пользователя много нерелевантных объектов 181\n",
      "У этого пользователя много нерелевантных объектов 181\n",
      "У этого пользователя много нерелевантных объектов 454\n",
      "У этого пользователя много нерелевантных объектов 637\n"
     ]
    }
   ],
   "source": [
    "dct_val = {} # В данном словаре находятся валидационные датасеты для каждого пользователя, купившего хотя бы 70 товаров. \n",
    "np.random.seed(1)\n",
    "for u in users_in_val:\n",
    "    sample = ml[ml[\"user\"] == u].copy()\n",
    "\n",
    "    val = sample.sample(n=15).copy()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    val.rating[val.rating < 4] = 0 \n",
    "    val.rating[val.rating == 5] = 1\n",
    "    val.rating[val.rating == 4] = 0.5\n",
    "\n",
    "    \n",
    "    while (np.array(val.rating) == 0).sum() > 13: # если в выборку попали более 12 нерелевантных значений\n",
    "        val = sample.sample(n=15)\n",
    "        \n",
    "        val.rating[val.rating < 4] = 0 \n",
    "        val.rating[val.rating == 5] = 1\n",
    "        val.rating[val.rating == 4] = 0.5\n",
    "        \n",
    "        print(\"У этого пользователя мало релевантных объектов\", u)\n",
    "        \n",
    "        \n",
    "    ml = ml.drop(np.array(val.index), axis=0)\n",
    "    \n",
    "    dct_val[u] = val\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf2827",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "id": "5111ab08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_for_ranksvd = pivot_to_df(ml, \"user\", \"item\", \"rating\") # df for RankSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d555676",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LambdaRank_movie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dccd57",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Алгоритм немного модифицируем. \n",
    "### Теперь в качестве признаков используем признаки из разложения SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "6cff8c03",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LambdaRank_movie:\n",
    "    def __init__(self,lr=0.1, sigma=1, num_epochs=3, seed=1, metric=NDCG,reg=0.05):\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.reg = 0.05\n",
    "        self.num_epochs = num_epochs\n",
    "        self.seed = seed\n",
    "        self.reg=reg\n",
    "        \n",
    "    def _create_features(self, th_user, th_item):\n",
    "        \"\"\"\n",
    "        Gets value of user, value of item. Returns vector of features of item th_item for query (in our case user) th_user\n",
    "        \"\"\"\n",
    "\n",
    "        pq = self.P[th_user-1,:] * self.Q[:,th_item-1] # в матрице индекс на 1 меньше\n",
    "        p_u = np.array([self.b_u[th_user-1]])\n",
    "        p_i = np.array([self.b_i[th_item-1]])\n",
    "        p_mu = np.array([self.mu])\n",
    "\n",
    "        x_features = np.concatenate((p_mu,p_u, p_i, pq)).reshape(-1,1)\n",
    "        \n",
    "        return x_features\n",
    "        \n",
    "    def fit(self,P_input, Q_input, b_u,b_i,mu, ml):\n",
    "        \"\"\"\n",
    "        На вход принимает четыре матрицы: P, Q, b_u, b_i, полученные факторизацией R.\n",
    "        Для каждого запроса (в нашем случае для каждого пользователя)\n",
    "            и для каждого предемета считается вектор признаков следующим образом:\n",
    "            \n",
    "        features(u,i) = (mu,b_u, b_i, P_u1*Q_i1, ...,P_uf*Q_if).\n",
    "        Помимо этого, принимает сводную таблицу ml со столбцами user, item, rating.\n",
    "        Модель обучается стохастическим градиентым спуском. \n",
    "        \"\"\"\n",
    "\n",
    "        self.P = P_input\n",
    "        self.Q = Q_input\n",
    "        self.b_u = b_u\n",
    "        self.b_i = b_i\n",
    "        self.mu = mu\n",
    "        \n",
    "        \n",
    "        dct_ml = {} \n",
    "        dct_size_of_user = {}\n",
    "        total_size = 0 # подсчет количества оцененных объектов\n",
    "\n",
    "        for u in ml.user.unique():\n",
    "            dct_ml[u] = ml[ml[\"user\"] == u].sort_values(\"rating\", ascending=False) # нужно ли копировать? чтобы случайно не изменить ml?\n",
    "            \n",
    "            dct_size_of_user[u] = len(dct_ml[u])\n",
    "            total_size += len(dct_ml[u])\n",
    "\n",
    "            \n",
    "        n_factors = self.P.shape[1]\n",
    "            \n",
    "        w = np.random.randn(1,n_factors + 1 + 1 + 1) # P_u * Q_i + b_u + b_i + mu\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "\n",
    "            for user in tqdm.tqdm(ml.user.unique()):\n",
    "                \n",
    "            \n",
    "                current_df = dct_ml[user].copy()\n",
    "                \n",
    "                # расчитываем a(x,w) для каждой пары (u,i) в current_df -> array\n",
    "                lst_values = []\n",
    "                for j in range(len(current_df)):\n",
    "                    row = current_df.iloc[j]\n",
    "         \n",
    "                    features = self._create_features(int(row[\"user\"]), int(row[\"item\"])) # почему-то берется float\n",
    "                    \n",
    "                    lst_values.append(float(w@features))\n",
    "                    \n",
    "                arr_values = np.array(lst_values)\n",
    "                zero = np.zeros(len(arr_values))\n",
    "                for pos, i in enumerate(np.argsort(-arr_values)): # почему во возрастанию???\n",
    "                    zero[i] = pos\n",
    "\n",
    "                current_df[\"my_order\"] = zero # единицу не прибавил\n",
    "                \n",
    "                \n",
    "                # берем случайную пару и делаем шаг\n",
    "                \n",
    "                for i in range(len(current_df)): # n\n",
    "   \n",
    "                    n_1, n_2 = np.sort(np.random.choice(range(len(current_df)), 2, replace=False)) # объекты в датасете отсортированы!\n",
    "                    \n",
    "\n",
    "                    a_1 = current_df.iloc[n_1]\n",
    "                    a_2 = current_df.iloc[n_2]\n",
    "        \n",
    "                    u1, i1, r1, o1 = [int(a_1[i]) if i!=2 else float(a_1[i]) for i in range(len(a_1))]\n",
    "                    u2, i2, r2, o2 = [int(a_2[i]) if i!=2 else float(a_2[i]) for i in range(len(a_2))]\n",
    "\n",
    "                    assert (type(u1) == int) and (type(i1) == int) and (type(r1) == float) and (type(o1) == int) \n",
    "                    assert (type(u2) == int) and (type(i2) == int) and (type(r2) == float) and (type(o2) == int) \n",
    "                    \n",
    "                    o1 += 1\n",
    "                    o2 += 1 # так как при сортировке начинается с 0\n",
    "                    \n",
    "                    x1 = self._create_features(u1, i1)\n",
    "                    x2 = self._create_features(u2, i2)     \n",
    "\n",
    "                    if r1 > r2 or r2> r1:\n",
    "                        delta_NDCG = np.abs((r1 / np.log(1 + o1) + r2 / np.log(1 + o2)) - (r1 / np.log(1 + o2) + r2 / np.log(1 + o1)))\n",
    "                        w = w + self.lr * self.sigma / (1 + np.exp(self.sigma * float(w@(x1-x2)))) * delta_NDCG * (x1 - x2).reshape(w.shape) - self.reg*w\n",
    "\n",
    "                \n",
    "        # trainig is completed\n",
    "        \n",
    "        self.w = w\n",
    "        \n",
    "        \n",
    "    def predict_one_order(self,pivot_predict):\n",
    "        \"\"\"\n",
    "        На вход ожидается сводная таблица валидации для одного пользователя.\n",
    "        \"\"\"\n",
    "        pivot = pivot_predict.copy()\n",
    "        pred = np.zeros(shape=len(pivot.index))\n",
    "        for i in range(len(pivot.index)):\n",
    "            user, item = list(map(int, list(pivot.iloc[i])))\n",
    "            \n",
    "\n",
    "            \n",
    "            features = self._create_features(user,item)\n",
    "            pred[i] = float(self.w @ features)\n",
    "            \n",
    "   \n",
    "        return np.argsort(pred).reshape(1,-1)[:,::-1] # возвращаем отранжированные индексы\n",
    "        \n",
    "    def predict_order_all(self,dct_val, len_of_order):\n",
    "        \"\"\"\n",
    "        The function gets dictionary in which keys are users and values corresponding pivot_table need to be ranked.\n",
    "        \"\"\"\n",
    "        predicted_orders = np.zeros((1,len_of_order))\n",
    "        true_ratings_arr = np.zeros((1,len_of_order))\n",
    "        for key in dct_val:\n",
    "\n",
    "            order_of_indices = (self.predict_one_order(dct_val[key].drop(\"rating\",axis=1))).astype(np.int32) # getting the order\n",
    "            true_ratings = np.array(dct_val[key][\"rating\"]).reshape(1,-1)\n",
    "            \n",
    "            predicted_orders = np.concatenate((predicted_orders, order_of_indices))\n",
    "            true_ratings_arr = np.concatenate((true_ratings_arr, true_ratings))\n",
    "            \n",
    "        \n",
    "        return predicted_orders[1:].astype(np.int32),true_ratings_arr[1:]\n",
    "        \n",
    "        \n",
    "    def compute_metric_for_all_queries(self,dct_val, len_of_order, n, metric):\n",
    "        \"\"\"\n",
    "        Function gets dictionary in which keys are users and values corresponding pivot_table need to be ranked \n",
    "            , length of order,  n in NDCG\n",
    "        \"\"\"\n",
    "        \n",
    "        predicted_orders, true_ratings_arr = self.predict_order_all(dct_val, len_of_order)\n",
    "        comp_metric = metric(predicted_orders, true_ratings_arr,n) if metric is NDCG or metric is MAP else (\n",
    "                                                                                metric(predicted_orders, true_ratings_arr))\n",
    "\n",
    "        return comp_metric\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162a63a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RankSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b6f35",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### В этом блоке SVD, сконструированный в прошлом домашнем задании, будет модифицирован для решения задач ранжирования.\n",
    "#### В последствии алгоритм будет использоваться для формирования признаков пары (пользователь, предмет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "899ce47f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RankSVD:\n",
    "    def __init__(self, n_factors=5, n_epochs=10, lr=0.001,reg=0.02,random_state=1):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_factors = n_factors\n",
    "        self.reg = reg\n",
    "        self.random_state = random_state\n",
    "        self.lr=lr\n",
    "    \n",
    "        \n",
    "    def compute_us_U(self,RR, P,Q, I,mu, mask, notna_1):\n",
    "        us = (np.sum((RR - P@Q - I - mu)*mask,axis=1)/notna_1).reshape(-1,1) # уцмножаю на маску, чтобы усреднение делать только по известным меткам\n",
    "        U = us*np.ones_like(RR)\n",
    "        return us, U\n",
    "\n",
    "    def compute_it_I(self,RR,P,Q,U,mu, mask, notna_0):\n",
    "        it = np.sum((RR - P@Q - U - mu)*mask, axis=0) / notna_0\n",
    "        I = it*np.ones_like(RR)\n",
    "        return it, I\n",
    "    \n",
    "\n",
    "    def _als(self,df_train):\n",
    "\n",
    "        n_factors = self.n_factors\n",
    "        random.seed(3)\n",
    "        np.random.seed(3)\n",
    "        RR = df_train.fillna(0).to_numpy()\n",
    "\n",
    "        P = np.random.random((RR.shape[0],n_factors))\n",
    "        Q = np.random.random((n_factors,RR.shape[1]))\n",
    "        mask = RR != 0 \n",
    "        R_est = RR + (P@Q)*~mask\n",
    "        not_null = mask.sum()\n",
    "        us = np.random.random((RR.shape[0],1))\n",
    "        it = np.random.random((1,RR.shape[1]))\n",
    "\n",
    "        U = us*np.ones_like(RR) \n",
    "\n",
    "        I = it*np.ones_like(RR)\n",
    "        \n",
    "\n",
    "        notna_0 = mask.sum(axis=0) + 0.00001\n",
    "        notna_1 = mask.sum(axis=1) + 0.00001\n",
    "        mu = np.ones_like(RR) * RR.sum() / not_null\n",
    "\n",
    "        for _ in range(self.n_epochs):\n",
    "            us, U = self.compute_us_U(RR, P,Q, I,mu, mask, notna_1)\n",
    "            it, I = self.compute_it_I(RR,P,Q,U,mu, mask, notna_0)\n",
    "\n",
    "            R_est = RR + (P@Q+I+U+mu)*~mask\n",
    "            P = (np.linalg.inv((Q@Q.T)) @ (Q@R_est.T - Q@(U.T+I.T + mu.T))).T\n",
    "\n",
    "            R_est = RR + (P@Q+I+U+mu)*~mask   \n",
    "            Q = (np.linalg.inv((P.T@P))@(P.T @ R_est - P.T@(U+I+mu)))\n",
    "    \n",
    "        self.mu = mu\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.I = I\n",
    "        self.U = U\n",
    "\n",
    "    def fit(self,df_train_):\n",
    "        np.random.seed(self.random_state)\n",
    "        df_train = df_train_.copy()\n",
    "        self._als(df_train)\n",
    "\n",
    "    def predict_one_order(self,pivot_predict):\n",
    "        \"\"\"\n",
    "        На вход ожидается сводная таблица валидации для одного пользователя.\n",
    "        \"\"\"\n",
    "        pivot = pivot_predict.copy()\n",
    "        pred = np.zeros(shape=len(pivot.index))\n",
    "        restored_R = self.P @ self.Q + self.U + self.I + self.mu\n",
    "        \n",
    "        for i in range(len(pivot.index)):\n",
    "            user, item = list(map(int, list(pivot.iloc[i])))\n",
    "            \n",
    "            user -= 1\n",
    "            item -= 1\n",
    "            \n",
    "            pred[i] = restored_R[user,item]\n",
    "            \n",
    "   \n",
    "        return np.argsort(pred).reshape(1,-1)[:,::-1] # возвращаем отранжированные индексы\n",
    "    \n",
    "    \n",
    "    def predict_order_all(self, dct_val, len_of_order):\n",
    "        \"\"\"\n",
    "        The function gets dictionary in which keys are users and values corresponding pivot_table need to be ranked.\n",
    "        \"\"\"\n",
    "        predicted_orders = np.zeros((1,len_of_order))\n",
    "        true_ratings_arr = np.zeros((1,len_of_order))\n",
    "        for key in dct_val:\n",
    "\n",
    "            order_of_indices = (self.predict_one_order(dct_val[key].drop(\"rating\",axis=1))).astype(np.int32) # getting the order\n",
    "            true_ratings = np.array(dct_val[key][\"rating\"]).reshape(1,-1)\n",
    "            \n",
    "            predicted_orders = np.concatenate((predicted_orders, order_of_indices))\n",
    "            true_ratings_arr = np.concatenate((true_ratings_arr, true_ratings))\n",
    "            \n",
    "        \n",
    "        return predicted_orders[1:].astype(np.int32),true_ratings_arr[1:]\n",
    "    \n",
    "    \n",
    "    def compute_metric_for_all_queries(self,dct_val, len_of_order, n, metric):\n",
    "        \"\"\"\n",
    "        Function gets dictionary in which keys are users and values corresponding pivot_table need to be ranked \n",
    "            , length of order,  n in NDCG\n",
    "        \"\"\"\n",
    "        \n",
    "        predicted_orders, true_ratings_arr = self.predict_order_all(dct_val, len_of_order)\n",
    "        comp_metric = metric(predicted_orders, true_ratings_arr,n) if metric is NDCG or metric is MAP else (\n",
    "                                                                                metric(predicted_orders, true_ratings_arr))\n",
    "\n",
    "        return comp_metric\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "6268a4a8",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd = RankSVD(n_factors=1)\n",
    "svd.fit(df_for_ranksvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6fc45",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing LambdaRank_movie on Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e1ed2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В исходном датасете имеются оценки 5,4,...1. \n",
    "Переведем их в соответствующие оценки, отражающие релевантность предмета. \\\n",
    "5 -> 1 \\\n",
    "4 -> 0.5 \\\n",
    "3 -> 0\\\n",
    "2 -> 0 \\\n",
    "1 -> 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "b275e2e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_ml = ml.copy()\n",
    "\n",
    "new_ml.rating[new_ml.rating < 3] = 0\n",
    "new_ml.rating[new_ml.rating == 4] = 0.5\n",
    "new_ml.rating[new_ml.rating ==5] = 1\n",
    "new_ml.rating[new_ml.rating ==3] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f7968",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Формируем матрицы, которые подаются на вход LambdaRank_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "16c2b736",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P_input = svd.P\n",
    "Q_input = svd.Q\n",
    "b_u = svd.U[:,1]\n",
    "b_i = svd.I[1,:]\n",
    "mu = svd.mu[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94ba4d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Обучаем LambdaRank_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "93d4e097",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:24<00:00, 39.00it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 39.05it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 39.06it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 39.06it/s]\n"
     ]
    }
   ],
   "source": [
    "lambdarank = LambdaRank_movie(lr=0.005, sigma=2, num_epochs=4, seed=1,reg=0)\n",
    "\n",
    "df = lambdarank.fit(P_input, Q_input, b_u, b_i, mu, new_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d9247",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Сравниваем качество моделей по метрике NDCG\n",
    "### Рекомендация обычно представляется в виде списка, блока, т.д. Поэтому помимо точности алгоритма, необходимо учитывать еще и порядок. Например, рекомендация в Youtube должна учитывать порядок, поскольку полезность модели будет тем выше, чем меньше пользователю придется листать до нужного контента.\n",
    "### На наш взгляд, метрика NDCG удовлетворяет этим свойствам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "76b1832b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "NDCG@3 lambdarank 0.6563426513694647\n",
      "NDCG@3 svd 0.6562748048082077\n",
      "--------\n",
      "NDCG@5 lambdarank 0.6752036050568428\n",
      "NDCG@5 svd 0.6718754990370885\n",
      "--------\n",
      "NDCG@10 lambdarank 0.7622794998195926\n",
      "NDCG@10 svd 0.7612044572515383\n"
     ]
    }
   ],
   "source": [
    "for n in [3,5,10]:\n",
    "    print(\"--------\")\n",
    "    print(f\"NDCG@{n} lambdarank\",np.mean(lambdarank.compute_metric_for_all_queries(dct_val,15,n,NDCG)))\n",
    "    print(f\"NDCG@{n} svd\",np.mean(svd.compute_metric_for_all_queries(dct_val,15,n, NDCG)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f8388",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## В данном примере LambdaRank лишь незначительно лучше SVDRank, поскольку признаки, используемые в алгоритме LambdaRank и SVDRank тождественны. Кроме того, также как и в первом алгоритме во втором используется линейная комбинация.\n",
    "\n",
    "## Однако, качество все же выше во всех трех экспериментах, что объясняется настройкой именно на метрику NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deef2f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
